# ICCV2017-Robust Video Super-Resolution with Learned Temporal Dynamics

## 亮点

一个学习时间动态的模型。

视频超分辨率（SR）旨在从本地时间窗口中的多个低分辨率（LR）帧生成高分辨率（HR）帧。

用于视频SR的关系有两种类型：帧内空间关系和帧间时间关系。为了解决这个问题，帧间时间关系与帧内空间关系同样重要。

如何有效地利用时间信息,从两个方面解决:

- 提出了一种时间自适应神经网络，它可以自适应地确定时间依赖性的最佳尺度。在将各种时间尺度上的滤波器自适应地聚合之前，将其应用于输入LR序列
- 使用空间对齐网络减少了相邻帧之间运动的复杂性，该网络比竞争对齐方法更坚固，更有效，并且可以以端到端的方式与时间自适应网络共同训练。

## 1. 介绍

在Image SR上，已经成功地证明了神经网络捕获空间关系能力极强[ 4，30，5，14，15，26，6 ]
与帧内空间关系相比，帧间时间关系对于视频SR更重要，因为视觉系统的研究表明，人类视觉系统对运动更敏感[ 7]

因此，对于视频SR算法而言，捕获运动信息对视觉感知的影响并对其建模至关重要。为了满足这种需求，提出了许多视频SR算法[ 8，28，2，20，23，17 ]


## 2. VSR 相关工作

VSR的深度学习。

首先在不同的参数设置下通过运动补偿生成一组SR草稿，然后使用CNN从所有草稿中重建HR帧。[ 17 ]

通过沿时间维度扩展单个图像SR的SRCNN来避免显式的运动估计，从而形成一个递归卷积网络以捕获长期的时间依赖性。[ 9 ]

在固定的时间尺度上扩展SRCNN并从光学流信息中对齐的帧中提取特征。[12]


## 3. 方法-Temporal Adaptive Neural Network

### 3.1 方法总览

对于LR视频序列，我们的模型旨在从一组本地LR帧估计HR帧。

视频SR的主要挑战在于正确利用时间信息来处理各种类型的运动。为了解决这个问题，我们设计了一个神经网络来自适应地为视频SR选择最佳的时间尺度。

网络具有许多SR推理分支。

$\left\{B_{i}\right\}_{i=1}^{N}$

每个$B_i$在不同的时间尺度i上工作，并使用其对尺度的时间依赖性来预测HR估计值。

我们设计了一个额外的时间调制分支T，以确定最佳的时间尺度，并基于运动信息在像素级别自适应地组合了所有HR估计。所有SR推理分支和时间调制分支都合并并在一个统一网络中共同学习。最终估计的HR帧是从所有SR推理分支的估计值中汇总的，其中考虑了各种时间尺度上的运动信息。时间自适应网络的概述如图1所示
![](https://aigroupz-1258285787.cos.ap-shanghai.myqcloud.com/2019/11/04/15721015787753.jpg)

### 3.2 网络架构

#### SR推理分支
 
基于ESPCN [ 26 ]的SR模型，并在每个SR信息中使用了它。为什么用ESPCN？因为它的SR准确性高且计算成本低。

SR推理分支$B_i$在$2i-1$个连续的LR帧上工作。
 
c表示每个输入LR帧的通道数。第一层SR推理分支$B_i$的滤波器的时间长度为$2i-1$，第一层的卷积滤波器被定制为具有$（2i - 1）× c$个通道。

选定的线性单位（ReLU）[ 24 ]作为第一层和第二层的激活函数。(可以试试gelu？)
 
SR推理分支不局限于使用ESPCN，基于SR的模型都可以，比如换成SRCNN等。
 
输出：$B_i$为最后的HR帧。
 
 
#### 时间调制分支T
 
该分支的原理是根据运动信息学习模型在不同时间尺度上的选择性。

作者建议在每个HR估计值上分配像素级聚合权重，实际上，该分支应用于最大的时间尺度。

即对于N个 SR推理分支的模型，时间调制分支将2 N - 1个连续帧作为输入。

#### 聚合

每个SR推理分支的输出都与时间调制分支中的相应权重图进行逐像素乘积，然后求和以形成最终估计的HR帧。

### 3.3 训练目标

在target HR帧和预测输出之间求loss：

$$\min _{\Theta} \sum_{j}\left\|F\left(\mathbf{y}^{(j)} ; \Theta\right)-\mathbf{x}^{(j)}\right\|_{2}^{2}$$

- 其中$F\left(\mathbf{y}^{(j)} ; \Theta\right)$是网络输出
- $x^{(j)}$是j-th HR帧
- $y^{(j)}$是j-th 所有相关的LR帧。
-  $Θ$ 是模型参数。

更进一步，如果用额外的参数$\theta_{w}$ ，函数 $W\left(\mathbf{y} ; \theta_{w}\right)$ 表示时间调制分支，损失函数为：

$$
\min _{\theta_{w},\left\{\theta_{B_{i}}\right\}_{i=1}^{N}} \sum_{j}\left\|\sum_{i=1}^{N} W_{i}\left(\mathbf{y}^{(j)} ; \theta_{w}\right) \odot F_{B_{i}}\left(\mathbf{y}^{(j)} ; \theta_{B_{i}}\right)-\mathbf{x}^{(j)}\right\|_{2}^{2}$$

- $F_{B_{i}}\left(\mathbf{y}^{(j)} ; \theta_{B_{i}}\right)$是SR推理链$B_i$的输出

作者在实践中，首先使用与训练目标相同的HR帧，像Loss（1）一样分别训练每个SR推理分支$B_i$，得到模型A。

然后在使用Loss（2）训练时间自适应网络（temporal adaptive
network）时，使用A初始化SR推理分支。这种训练策略在不牺牲SR的预测准确性的情况下，极大地加快了收敛速度。

## 4. 空间对齐方法

对于视频SR，人们通常在空间上对准相邻帧以增加时间相干性，并且图像对齐作为预处理步骤已被证明对模型有好处[ 17，12 ]。

因此，作者研究了几种图像对齐方法，以便为时间自适应网络提供更好的运动补偿帧。

### 4.1 纠正光流对准（Rectified Optical Flow Alignment）

由于复杂的运动很难建模，基于常规光流的图像对齐使用错误的运动估算可能会引入伪影，会传播到以后的SR步骤并对其产生不利影响。 

作者尝试将补丁级别的运动简化为整数转换，以避免插值可能会导致模糊或混叠。 给定补丁及其光流，我们估计整数平移沿水平和垂直方向取整
所有像素的平均水平和垂直位移在此补丁中。 该方案称为纠正光流对准，被证明对以下方面更有利SR比传统的基于光流的图像对齐。

### 4.2 空间对齐网络 （Spatial Alignment Network）

![](https://aigroupz-1258285787.cos.ap-shanghai.myqcloud.com/2019/11/04/15721612969360.jpg)

每次空间对准网络将一个LR参考帧和一个LR相邻帧（作为源帧）作为输入，并生成该相邻帧的对准版本作为输出。

最后loss为：

$$\min _{\left\{\Theta, \theta_{L}\right\}} \sum_{j}\left\|F\left(\mathbf{y}^{(j)} ; \mathbf{\Theta}\right)-\mathbf{x}^{(j)}\right\|_{2}^{2}+\lambda \sum_{j} \sum_{k \in \mathcal{N}_{j}}\left\|\hat{\theta}_{S T}^{(k)}-\theta_{S T}^{(k)}\right\|_{2}^{2}$$

- $\mathcal{N}_{j}: LR帧集合关联的j-th HR帧$
